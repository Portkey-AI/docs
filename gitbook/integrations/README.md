# Integrations

Portkey effortlessly melds with a host of major LLM providers, such as OpenAI and Anthropic, and is seamlessly compatible with projects like Langchain and Llamaindex. Our native integrations enable you to harness Portkeyâ€™s robust features, bringing your apps to production with enriched capabilities like load balancing, fallbacks, observability, caching, and many more.

## Integration Methods

Integrating Portkey is a straightforward process. Choose your preferred method below and follow the instructions.

{% content-ref url="llms/open-ai-sdk.md" %}
[open-ai-sdk.md](llms/open-ai-sdk.md)
{% endcontent-ref %}

{% content-ref url="llms/anthropic-sdk.md" %}
[anthropic-sdk.md](llms/anthropic-sdk.md)
{% endcontent-ref %}

{% content-ref url="langchain.md" %}
[langchain.md](langchain.md)
{% endcontent-ref %}

{% content-ref url="llamaindex/" %}
[llamaindex](llamaindex/)
{% endcontent-ref %}

## Direct Integration

With Portkeyâ€™s Rest API, you can directly integrate essential features like the AI Gateway, Observability, and Caching into your app, ensuring optimal performance and user satisfaction.

{% content-ref url="rest-api/" %}
[rest-api](rest-api/)
{% endcontent-ref %}

## ðŸ“¬ Request a New Integration

Empowering your transition to production is our chief priority. If you have a particular integration in mind, weâ€™re all ears! Send us an email at [support@portkey.ai](mailto:support@portkey.ai) or connect with us on [Discord](https://discord.com/invite/DD7vgKK299).
