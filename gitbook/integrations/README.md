# ü§ù Integrations

Portkey effortlessly melds with a host of major LLM providers, such as OpenAI and Anthropic, and is seamlessly compatible with projects like Langchain and Llamaindex. Our native integrations enable you to harness Portkey‚Äôs robust features, bringing your apps to production with enriched capabilities like load balancing, fallbacks, observability, caching, and many more.

## Integration Methods

Integrating Portkey is a straightforward process. Choose your preferred method below and follow the instructions.

{% content-ref url="llm-providers/open-ai-sdk.md" %}
[open-ai-sdk.md](llm-providers/open-ai-sdk.md)
{% endcontent-ref %}

{% content-ref url="llm-providers/anthropic-sdk.md" %}
[anthropic-sdk.md](llm-providers/anthropic-sdk.md)
{% endcontent-ref %}

{% content-ref url="langchain.md" %}
[langchain.md](langchain.md)
{% endcontent-ref %}

{% content-ref url="llamaindex/" %}
[llamaindex](llamaindex/)
{% endcontent-ref %}

## Direct Integration

With Portkey‚Äôs Rest API, you can directly integrate essential features like the AI Gateway, Observability, and Caching into your app, ensuring optimal performance and user satisfaction.

{% content-ref url="rest-api/" %}
[rest-api](rest-api/)
{% endcontent-ref %}

## üì¨ Request a New Integration

Empowering your transition to production is our chief priority. If you have a particular integration in mind, we‚Äôre all ears! Send us an email at [support@portkey.ai](mailto:support@portkey.ai) or connect with us on [Discord](https://discord.com/invite/DD7vgKK299).
