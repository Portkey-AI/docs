# LLMs

### Supported Providers

Portkey supports multiple providers through its [official SDK](../../sdk/) as well as the SDKs of the respective providers. Along with this, Portkey also natively integrates with multiple LLM providers through its [rest API](../rest-api/) and through integrations with projects like [Langchain](../langchain.md) and [Llamaindex](../llamaindex/).

<table><thead><tr><th>Provider</th><th>Portkey SDK</th><th>Client SDK (Python)</th><th>Client SDK (Node)</th><th data-hidden>Portkey SDK</th><th data-hidden>Client SDK (Python)</th><th data-hidden>Client SDK (Node)</th><th data-hidden>Proxy API</th></tr></thead><tbody><tr><td>OpenAI</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td></td></tr><tr><td>Azure OpenAI</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td></td></tr><tr><td>Anthropic</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td><td>âœ…</td></tr><tr><td>Cohere</td><td>âœ…</td><td>ðŸš§</td><td>ðŸš§</td><td>âœ…</td><td>ðŸš§</td><td>ðŸš§</td><td>âœ…</td></tr><tr><td>Hugging Face (invite-only)</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Anyscale (invite-only)</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr></tbody></table>

### Detailed Overview of LLM Functions by Provider

<table><thead><tr><th width="193">Provider</th><th>Rest API</th><th>SDK</th></tr></thead><tbody><tr><td>OpenAI</td><td>ChatCompletions, Completions, Embed, Images, Audio, Files, Fine-tunes, Moderations, Edits</td><td>ChatCompletions, Completions</td></tr><tr><td>Azure OpenAI</td><td>ChatCompletions, Completions, Embed, Images, Audio, Files, Fine-tunes, Moderations, Edits</td><td>ChatCompletions, Completions</td></tr><tr><td>Anthropic</td><td>Completions</td><td>Completions</td></tr><tr><td>Cohere</td><td>Generate, Embed, Classify, Tokenize, Detokenize, Detect-language, Summarise, Rerank</td><td>Generate</td></tr><tr><td>Hugging Face</td><td>Inference</td><td>(In Beta)</td></tr><tr><td>Anyscale</td><td>(In Beta)</td><td>(In Beta)</td></tr></tbody></table>

{% hint style="info" %}
**Please Note**: This table will be regularly updated as we continue to expand our support for various LLM providers and their functions. Some of the unavailable functions might already be in beta. Do reach out on [Discord](https://discord.com/invite/DD7vgKK299) if you need something which is missing here.
{% endhint %}

If you have any questions about LLM support or if you're interested in a provider or function that's not currently listed, please reach out [on Discord](https://discord.com/invite/DD7vgKK299) or [send us a mail](mailto:support@portkey.ai). We're always looking to enhance our offerings based on your needs.
