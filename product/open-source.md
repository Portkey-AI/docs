# Open Source

## [Portkey AI Gateway](https://github.com/portkey-ai/rubeus)

We have open sourced our battle-tested AI Gateway to the community - it connects to 200+ LLMs with a unified interface and a single endpoint, and lets you effortlessly setup fallbacks, load balancing, retries, and more.

This gateway is in production at Portkey processing billions of tokens every day.

#### [Contribute here](https://github.com/portkey-ai/rubeus).

***

## [AI Grants Finder](https://grantsfinder.portkey.ai/)

Community resource for AI builders to find **`GPU credits`**, **`grants`**, **`AI accelerators`**, or **`investments`** - all in a single place. Continuously updated, and sometimes also featuring [exclusive deals](https://twitter.com/PortkeyAI/status/1692463628514156859).

{% embed url="https://airtable.com/appUjtBcdLQIgusqW/shrAU1e4M5twTmRal" %}

***

## [Gateway Reports](https://portkey.ai/blog/tag/benchmarks/)

We collaborate with the community to dive deep into how the LLMs & their inference providers are performing at scale, and publish gateway reports. We track latencies, uptime, cost changes, fluctuations across various modalitites like time-of-day, regions, token-lengths, and more.

#### Report 1: [GPT-4 is getting faster](https://portkey.ai/blog/gpt-4-is-getting-faster/)

<figure><img src="../.gitbook/assets/image (1) (1) (1) (2) (1) (1).png" alt=""><figcaption></figcaption></figure>

#### **Please reach out** [**on Discord**](https://discord.gg/9sfE5ZYv) **to collaborate on our next report!**

***

## **Collaborations**

Portkey supports various open source projects with additional production capabilities through its custom integrations, and the list is always growing:

* ​[Langchain](https://python.langchain.com/docs/integrations/providers/portkey/) - Monitor and trace your Langchain queries
* ​[Llamaindex](https://gpt-index.readthedocs.io/en/latest/examples/llm/portkey.html)​ - Monitor & trace your requests, and also set up automated fallbacks & load balancing
* [GPT Prompt Engineer](https://github.com/mshumer/gpt-prompt-engineer) - Log all the prompt engineer runs and debug issues easily
* [Instructor](../welcome/integration-guides/instructor.md) - Extract structured outputs from LLMs and get full-stack observability over everything&#x20;
* [Promptfoo](../welcome/integration-guides/promptfoo.md) - Use Portkey prompts with Promptfoo to run evals and manage and version your prompt templates
* [Route to OSS LLMs](../welcome/integration-guides/ollama.md) - Connect Portkey to your locally hosted models
* [Autogen](../welcome/integration-guides/autogen.md) - Bring LLM interoperability and Portkey's reliability to your Autogen agents
